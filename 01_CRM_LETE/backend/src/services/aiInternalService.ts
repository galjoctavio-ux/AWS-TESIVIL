import { GoogleGenerativeAI } from '@google/generative-ai';
import dotenv from 'dotenv';
import { pool } from '../config/db';

dotenv.config();

const genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY || '');

// Prompt exclusivo para el resumen t√©cnico
const TECH_SUMMARY_PROMPT = `
Instrucciones del sistema:
Genera un contexto breve, claro y seguro basado exclusivamente en los √∫ltimos 30 mensajes del chat.

Objetivo:
Crear un resumen operativo para el t√©cnico SIN mostrar informaci√≥n sensible (Tel√©fono) y SIN copiar conversaciones de precios o ventas.

Formato del resumen:
Domicilio: (calle, n√∫mero, colonia, referencias exactas).
Problema reportado: (explica la falla el√©ctrica t√©cnica).
Detalles importantes: (puntos clave, horarios, advertencias).
Archivos/Fotos relevantes: (describe brevemente si se mencionan fotos).

Si no hay informaci√≥n suficiente, muestra la informaci√≥n que hayas encontrado y adem√°s escribe: "Informaci√≥n insuficiente para generar un resumen completo. Consultar detalles con administraci√≥n."

SIEMPRE termina con:
"Puedes contactar directamente al cliente desde este chat. Los mensajes que escribas empezar√°n con "Ing. (tu nombre) escribi√≥ este mensaje:". Los mensajes pueden tardar unos segundos en aparecer en el chat. S√© amable."
`;

const getChatHistoryForSummary = async (conversationId: number) => {
    try {
        // Traemos un poco m√°s de contexto (40 msgs) para que el resumen sea bueno
        const res = await pool.query(
            `SELECT sender_type, content FROM messages 
             WHERE conversation_id = $1 
             ORDER BY id ASC LIMIT 40`,
            [conversationId]
        );
        return res.rows.map(msg => ({
            role: msg.sender_type === 'CLIENT' ? 'user' : 'model',
            parts: [{ text: msg.content }]
        }));
    } catch (error) {
        console.error('Error obteniendo historial para resumen:', error);
        return [];
    }
};

// --- FUNCI√ìN PRINCIPAL ---
export const generateTechSummary = async (conversationId: number): Promise<void> => {
    console.log(`üë∑ Generando resumen t√©cnico interno para chat ${conversationId}...`);
    try {
        const history = await getChatHistoryForSummary(conversationId);

        // Si hay muy pocos mensajes, no gastamos tokens ni generamos ruido
        if (history.length < 2) {
            console.log("‚ö†Ô∏è Historial muy corto, se omite resumen.");
            return;
        }

        // Usamos un modelo 'flash' simple
        const model = genAI.getGenerativeModel({ model: 'gemini-2.5-flash' });

        // Aplanamos el chat a texto para que la IA lo lea como un documento
        const conversationText = history.map(h => `${h.role}: ${h.parts[0].text}`).join('\n');

        const finalPrompt = `${TECH_SUMMARY_PROMPT}\n\n--- CONVERSACI√ìN A ANALIZAR ---\n${conversationText}`;

        const result = await model.generateContent(finalPrompt);
        const summary = result.response.text();

        // Guardamos silenciosamente en la BD
        await pool.query(
            `UPDATE conversations SET tech_summary = $1 WHERE id = $2`,
            [summary, conversationId]
        );
        console.log(`‚úÖ Resumen guardado exitosamente para ID: ${conversationId}`);

    } catch (error) {
        console.error('‚ùå Error en aiInternalService:', error);
        // No lanzamos error para no romper el flujo del admin
    }
};
